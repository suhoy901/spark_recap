{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.3 스파크 SQL\n",
    "+ 스파크 SQL은 하이브 메타스토어를 사용하므로 하이브와 잘 연동됨\n",
    "    + 하이브 버전 설정: spark.sql.hive.metastore.version\n",
    "    + 초기화 방식 변경: spark.sql.hive.metastore.jars\n",
    "    + 클래스 접두사 설정: spark.sql.hive.metastore.sharedPrefixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.4 스파크 쿼리 실행방법\n",
    "+ 스파크 SQL CLI\n",
    "    ```\n",
    "    ./bin/spark-sql\n",
    "    ```\n",
    "+ 스파크 프로그래밍 SQL 인터페이스\n",
    "    ```\n",
    "    spark.sql(\"SELECT 1+1\").show()\n",
    "    ```\n",
    "+ 스파크 SQL 쓰리프트 JDBC/ODBC 서버\n",
    "    + 자바 데이터베이스 연결 인터페이스 제공\n",
    "    + 하이브 1.2.1. 버전의 HiveServer2에 맞추어 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-----------+\n",
      "|database|tableName|isTemporary|\n",
      "+--------+---------+-----------+\n",
      "+--------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "\"show tables\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|   DEST_COUNTRY_NAME|sum(count)|\n",
      "+--------------------+----------+\n",
      "|            Anguilla|        41|\n",
      "|              Russia|       176|\n",
      "|            Paraguay|        60|\n",
      "|             Senegal|        40|\n",
      "|              Sweden|       118|\n",
      "|            Kiribati|        26|\n",
      "|              Guyana|        64|\n",
      "|         Philippines|       134|\n",
      "|            Djibouti|         1|\n",
      "|            Malaysia|         2|\n",
      "|           Singapore|         3|\n",
      "|                Fiji|        24|\n",
      "|              Turkey|       138|\n",
      "|                Iraq|         1|\n",
      "|             Germany|      1468|\n",
      "|              Jordan|        44|\n",
      "|               Palau|        30|\n",
      "|Turks and Caicos ...|       230|\n",
      "|              France|       935|\n",
      "|              Greece|        30|\n",
      "+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### 프로그래밍 SQL 인터페이스\n",
    "spark.read.json(\"../BookSamples/data/flight-data/json/2015-summary.json\").createOrReplaceTempView(\"flight\")\n",
    "\n",
    "spark.sql(\n",
    "\"\"\"\n",
    "SELECT DEST_COUNTRY_NAME, sum(count)\n",
    "FROM flight GROUP BY DEST_COUNTRY_NAME\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-----------+\n",
      "|database|tableName|isTemporary|\n",
      "+--------+---------+-----------+\n",
      "|        |   flight|       true|\n",
      "+--------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "\"show tables\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.5 카탈로그\n",
    "+ 스파크의 가장 높은 추상화 단계\n",
    "+ 테이블, 데이터베이스, 함수를 조회하는 등 여러 가지 유용한 함수를 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.6 테이블\n",
    "+ DataFrame과 논리적으로 동일\n",
    "+ 스파크에서 테이블을 생성하면 default 데이터베이스에 등록됨\n",
    "+ 임시 테이블 개념이 없으며 데이터를 가지지 않은 뷰만 존재\n",
    "+ 관리형 테이블과 외부 테이블이 있으며 디스크에 저장된 파일을 이용해 테이블을 정의하면 외부 테이블을 활용하는 것임\n",
    "\n",
    "### 10.6.2 테이블 생성하기\n",
    "+ USING을 통해 포맷을 지정하지 않으면 스파크는 기본적으로 하이브 SerDe 설정을 사용해서 Reader, Writer 성능에 악영향을 줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\n",
    "\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS flights(\n",
    "    DEST_COUNTRY_NAME STRING, \n",
    "    ORIGIN_COUNTRY_NAME STRING, \n",
    "    count LONG\n",
    ")\n",
    "USING JSON \n",
    "OPTIONS (path '../BookSamples/data/flight-data/json/2015-summary.json')\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `OPTIONS (path '../BookSamples/data/flight-data/json/2015-summary.json')`는 해당 결로에 있는 데이터로 managed table을 생성하는 것\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-----------+\n",
      "|database|tableName|isTemporary|\n",
      "+--------+---------+-----------+\n",
      "| default|  flights|      false|\n",
      "|        |   flight|       true|\n",
      "+--------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|       United States|            Romania|   15|\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|            Ireland|  344|\n",
      "|               Egypt|      United States|   15|\n",
      "|       United States|              India|   62|\n",
      "|       United States|          Singapore|    1|\n",
      "|       United States|            Grenada|   62|\n",
      "|          Costa Rica|      United States|  588|\n",
      "|             Senegal|      United States|   40|\n",
      "|             Moldova|      United States|    1|\n",
      "|       United States|       Sint Maarten|  325|\n",
      "|       United States|   Marshall Islands|   39|\n",
      "|              Guyana|      United States|   64|\n",
      "|               Malta|      United States|    1|\n",
      "|            Anguilla|      United States|   41|\n",
      "|             Bolivia|      United States|   30|\n",
      "|       United States|           Paraguay|    6|\n",
      "|             Algeria|      United States|    4|\n",
      "|Turks and Caicos ...|      United States|  230|\n",
      "|       United States|          Gibraltar|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "\"select * from flights\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 해당 폴더를 지우는 명령어\n",
    "# ! rm -r -f ./spark-warehouse/flights_from_select\n",
    "\n",
    "# 특정 테이블에서 원하는 데이터만 추출해서 새로운 테이블을 생성(CTAS 패턴)\n",
    "spark.sql( \n",
    "\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS flights_from_select\n",
    "USING Parquet \n",
    "AS SELECT * FROM flights\n",
    "\"\"\") # spark-warehouse 폴더에 테이블 이름의 서브폴더가 생성되고 그 안에 파케이 파일이 저장됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|       United States|            Romania|   15|\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|            Ireland|  344|\n",
      "|               Egypt|      United States|   15|\n",
      "|       United States|              India|   62|\n",
      "|       United States|          Singapore|    1|\n",
      "|       United States|            Grenada|   62|\n",
      "|          Costa Rica|      United States|  588|\n",
      "|             Senegal|      United States|   40|\n",
      "|             Moldova|      United States|    1|\n",
      "|       United States|       Sint Maarten|  325|\n",
      "|       United States|   Marshall Islands|   39|\n",
      "|              Guyana|      United States|   64|\n",
      "|               Malta|      United States|    1|\n",
      "|            Anguilla|      United States|   41|\n",
      "|             Bolivia|      United States|   30|\n",
      "|       United States|           Paraguay|    6|\n",
      "|             Algeria|      United States|    4|\n",
      "|Turks and Caicos ...|      United States|  230|\n",
      "|       United States|          Gibraltar|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql( \n",
    "\"\"\"\n",
    "SELECT * FROM flights_from_select\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.6.3 외부 테이블 생성하기\n",
    "+ 외부 테이블의 메타데이터를 관리하지만 데이터 파일은 스파크에서 관리하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\n",
    "\"\"\"\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS\n",
    "    hive_flights(DEST_COUNTRY_NAME STRING, ORIGIN_COUNTRY_NAME STRING, count LONG)\n",
    "ROW FORMAT DELIMITED FIELDS TERMINATED BY ','\n",
    "LOCATION '../BookSamples/data/flight-data-hive'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------+\n",
      "|database|          tableName|isTemporary|\n",
      "+--------+-------------------+-----------+\n",
      "| default|            flights|      false|\n",
      "| default|flights_from_select|      false|\n",
      "| default|       hive_flights|      false|\n",
      "|        |             flight|       true|\n",
      "+--------+-------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "\"show tables\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|       United States|            Romania|   15|\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|            Ireland|  344|\n",
      "|               Egypt|      United States|   15|\n",
      "|       United States|              India|   62|\n",
      "|       United States|          Singapore|    1|\n",
      "|       United States|            Grenada|   62|\n",
      "|          Costa Rica|      United States|  588|\n",
      "|             Senegal|      United States|   40|\n",
      "|             Moldova|      United States|    1|\n",
      "|       United States|       Sint Maarten|  325|\n",
      "|       United States|   Marshall Islands|   39|\n",
      "|              Guyana|      United States|   64|\n",
      "|               Malta|      United States|    1|\n",
      "|            Anguilla|      United States|   41|\n",
      "|             Bolivia|      United States|   30|\n",
      "|       United States|           Paraguay|    6|\n",
      "|             Algeria|      United States|    4|\n",
      "|Turks and Caicos ...|      United States|  230|\n",
      "|       United States|          Gibraltar|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql( \n",
    "\"\"\"\n",
    "SELECT * FROM hive_flights\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\n",
    "\"\"\"\n",
    "CREATE EXTERNAL TABLE hive_flights2\n",
    "ROW FORMAT DELIMITED FIELDS TERMINATED BY ','\n",
    "LOCATION '../BookSamples/data/flight-data-hive' \n",
    "AS SELECT * FROM flights\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------+\n",
      "|database|          tableName|isTemporary|\n",
      "+--------+-------------------+-----------+\n",
      "| default|            flights|      false|\n",
      "| default|flights_from_select|      false|\n",
      "| default|       hive_flights|      false|\n",
      "| default|      hive_flights2|      false|\n",
      "|        |             flight|       true|\n",
      "+--------+-------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "\"show tables\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|       United States|            Romania|   15|\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|            Ireland|  344|\n",
      "|               Egypt|      United States|   15|\n",
      "|       United States|              India|   62|\n",
      "|       United States|          Singapore|    1|\n",
      "|       United States|            Grenada|   62|\n",
      "|          Costa Rica|      United States|  588|\n",
      "|             Senegal|      United States|   40|\n",
      "|             Moldova|      United States|    1|\n",
      "|       United States|       Sint Maarten|  325|\n",
      "|       United States|   Marshall Islands|   39|\n",
      "|              Guyana|      United States|   64|\n",
      "|               Malta|      United States|    1|\n",
      "|            Anguilla|      United States|   41|\n",
      "|             Bolivia|      United States|   30|\n",
      "|       United States|           Paraguay|    6|\n",
      "|             Algeria|      United States|    4|\n",
      "|Turks and Caicos ...|      United States|  230|\n",
      "|       United States|          Gibraltar|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "\"select * from hive_flights2\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.6.4 테이블에 데이터 삽입하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|count(DEST_COUNTRY_NAME)|\n",
      "+------------------------+\n",
      "|                     256|\n",
      "+------------------------+\n",
      "\n",
      "+------------------------+\n",
      "|count(DEST_COUNTRY_NAME)|\n",
      "+------------------------+\n",
      "|                     276|\n",
      "+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "\"\"\"\n",
    "SELECT count(DEST_COUNTRY_NAME) FROM flights_from_select\n",
    "\"\"\").show()\n",
    "\n",
    "spark.sql(\n",
    "\"\"\"\n",
    "INSERT INTO flights_from_select\n",
    "    SELECT * FROM flights LIMIT 20\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(\n",
    "\"\"\"\n",
    "SELECT count(DEST_COUNTRY_NAME) FROM flights_from_select\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+-------+\n",
      "|           col_name|data_type|comment|\n",
      "+-------------------+---------+-------+\n",
      "|  DEST_COUNTRY_NAME|   string|   null|\n",
      "|ORIGIN_COUNTRY_NAME|   string|   null|\n",
      "|              count|   bigint|   null|\n",
      "+-------------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql( # 메타 데이터 확인\n",
    "\"\"\"\n",
    "DESCRIBE TABLE flights\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기타 명령어\n",
    "+ DESCRIBE: 메타정보 확인\n",
    "+ SHOW PARTITIONS: 파티셔닝 스키마 정보 확인\n",
    "+ REFRESH: 캐싱된 항목을 갱신\n",
    "+ MSCK REPAIR TABLE: 관리하는 테이블의 파티션 정보를 새로 고침\n",
    "+ DROP TABLE: 외부 테이블을 제거하면 데이터는 삭제되지 않지마, 외부 테이블명을 이용해 데이터 조회는 안됨\n",
    "+ CACHE/UNCACHE TABLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.10 고급 주제\n",
    "+ 구조체, 리스트, 맵 세가지 타입이 존재\n",
    "\n",
    "#### 리스트\n",
    "+ 값의 리스트를 만드는 collect_list, 중복값을 제거하는 collect_set이 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+---------------+\n",
      "|            new_name|flight_counts|     origin_set|\n",
      "+--------------------+-------------+---------------+\n",
      "|            Anguilla|         [41]|[United States]|\n",
      "|            Paraguay|         [60]|[United States]|\n",
      "|              Russia|        [176]|[United States]|\n",
      "|             Senegal|         [40]|[United States]|\n",
      "|              Sweden|        [118]|[United States]|\n",
      "|            Kiribati|         [26]|[United States]|\n",
      "|              Guyana|         [64]|[United States]|\n",
      "|         Philippines|        [134]|[United States]|\n",
      "|            Djibouti|          [1]|[United States]|\n",
      "|            Malaysia|          [2]|[United States]|\n",
      "|           Singapore|          [3]|[United States]|\n",
      "|                Fiji|         [24]|[United States]|\n",
      "|              Turkey|        [138]|[United States]|\n",
      "|                Iraq|          [1]|[United States]|\n",
      "|             Germany|       [1468]|[United States]|\n",
      "|              Jordan|         [44]|[United States]|\n",
      "|               Palau|         [30]|[United States]|\n",
      "|              France|        [935]|[United States]|\n",
      "|Turks and Caicos ...|        [230]|[United States]|\n",
      "|              Greece|         [30]|[United States]|\n",
      "+--------------------+-------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "SELECT DEST_COUNTRY_NAME as new_name, collect_list(count) as flight_counts,\n",
    "    collect_set(ORIGIN_COUNTRY_NAME) as origin_set\n",
    "FROM flights GROUP BY DEST_COUNTRY_NAME\n",
    "\"\"\"\n",
    "spark.sql(sql).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+\n",
      "|   DEST_COUNTRY_NAME|array(1, 2, 3)|\n",
      "+--------------------+--------------+\n",
      "|       United States|     [1, 2, 3]|\n",
      "|       United States|     [1, 2, 3]|\n",
      "|       United States|     [1, 2, 3]|\n",
      "|               Egypt|     [1, 2, 3]|\n",
      "|       United States|     [1, 2, 3]|\n",
      "|       United States|     [1, 2, 3]|\n",
      "|       United States|     [1, 2, 3]|\n",
      "|          Costa Rica|     [1, 2, 3]|\n",
      "|             Senegal|     [1, 2, 3]|\n",
      "|             Moldova|     [1, 2, 3]|\n",
      "|       United States|     [1, 2, 3]|\n",
      "|       United States|     [1, 2, 3]|\n",
      "|              Guyana|     [1, 2, 3]|\n",
      "|               Malta|     [1, 2, 3]|\n",
      "|            Anguilla|     [1, 2, 3]|\n",
      "|             Bolivia|     [1, 2, 3]|\n",
      "|       United States|     [1, 2, 3]|\n",
      "|             Algeria|     [1, 2, 3]|\n",
      "|Turks and Caicos ...|     [1, 2, 3]|\n",
      "|       United States|     [1, 2, 3]|\n",
      "+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "SELECT DEST_COUNTRY_NAME, ARRAY(1, 2, 3) FROM flights\n",
    "\"\"\" # 직접 베열 입력\n",
    "spark.sql(sql).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "|   DEST_COUNTRY_NAME|array(1, 2, 3)[0]|\n",
      "+--------------------+-----------------+\n",
      "|       United States|                1|\n",
      "|       United States|                1|\n",
      "|       United States|                1|\n",
      "|               Egypt|                1|\n",
      "|       United States|                1|\n",
      "|       United States|                1|\n",
      "|       United States|                1|\n",
      "|          Costa Rica|                1|\n",
      "|             Senegal|                1|\n",
      "|             Moldova|                1|\n",
      "|       United States|                1|\n",
      "|       United States|                1|\n",
      "|              Guyana|                1|\n",
      "|               Malta|                1|\n",
      "|            Anguilla|                1|\n",
      "|             Bolivia|                1|\n",
      "|       United States|                1|\n",
      "|             Algeria|                1|\n",
      "|Turks and Caicos ...|                1|\n",
      "|       United States|                1|\n",
      "+--------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "SELECT DEST_COUNTRY_NAME, ARRAY(1, 2, 3)[0] FROM flights \n",
    "\"\"\" # 위치 인덱싱\n",
    "spark.sql(sql).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# collect_list로 count 값들을 묶음 \n",
    "sql = \"\"\"\n",
    "CREATE OR REPLACE TEMP VIEW flights_agg AS\n",
    "    SELECT DEST_COUNTRY_NAME, collect_list(count) as flight_counts\n",
    "    FROM flights GROUP BY DEST_COUNTRY_NAME\n",
    "\"\"\"\n",
    "spark.sql(sql).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------+\n",
      "|database|          tableName|isTemporary|\n",
      "+--------+-------------------+-----------+\n",
      "| default|            flights|      false|\n",
      "| default|flights_from_select|      false|\n",
      "| default|       hive_flights|      false|\n",
      "| default|      hive_flights2|      false|\n",
      "|        |             flight|       true|\n",
      "|        |        flights_agg|       true|\n",
      "+--------+-------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "\"show tables\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+\n",
      "|   DEST_COUNTRY_NAME|flight_counts|\n",
      "+--------------------+-------------+\n",
      "|            Anguilla|         [41]|\n",
      "|            Paraguay|         [60]|\n",
      "|              Russia|        [176]|\n",
      "|             Senegal|         [40]|\n",
      "|              Sweden|        [118]|\n",
      "|            Kiribati|         [26]|\n",
      "|              Guyana|         [64]|\n",
      "|         Philippines|        [134]|\n",
      "|            Djibouti|          [1]|\n",
      "|            Malaysia|          [2]|\n",
      "|           Singapore|          [3]|\n",
      "|                Fiji|         [24]|\n",
      "|              Turkey|        [138]|\n",
      "|                Iraq|          [1]|\n",
      "|             Germany|       [1468]|\n",
      "|              Jordan|         [44]|\n",
      "|               Palau|         [30]|\n",
      "|              France|        [935]|\n",
      "|Turks and Caicos ...|        [230]|\n",
      "|              Greece|         [30]|\n",
      "+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "select * from flights_agg\n",
    "\"\"\"\n",
    "spark.sql(sql).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|count|   DEST_COUNTRY_NAME|\n",
      "+-----+--------------------+\n",
      "|   41|            Anguilla|\n",
      "|   60|            Paraguay|\n",
      "|  176|              Russia|\n",
      "|   40|             Senegal|\n",
      "|  118|              Sweden|\n",
      "|   26|            Kiribati|\n",
      "|   64|              Guyana|\n",
      "|  134|         Philippines|\n",
      "|    1|            Djibouti|\n",
      "|    2|            Malaysia|\n",
      "|    3|           Singapore|\n",
      "|   24|                Fiji|\n",
      "|  138|              Turkey|\n",
      "|    1|                Iraq|\n",
      "| 1468|             Germany|\n",
      "|   44|              Jordan|\n",
      "|   30|               Palau|\n",
      "|  935|              France|\n",
      "|  230|Turks and Caicos ...|\n",
      "|   30|              Greece|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 반대로 동작\n",
    "sql = \"\"\"\n",
    "SELECT explode(flight_counts) as count, DEST_COUNTRY_NAME FROM flights_agg\n",
    "\"\"\"\n",
    "spark.sql(sql).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.10.2 함수\n",
    "+ SHOW FUNCTIONS\n",
    "+ SHOW SYSTEM FUNCTIONS\n",
    "+ SHOW USER FUNCTIONS\n",
    "+ SHOW FUNCTIONS \"S*\"\n",
    "+ SHOW FUNCTIONS LIKE \"collect*\"\n",
    "+ 사용자 정의 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+\n",
      "|count|power3(count)|\n",
      "+-----+-------------+\n",
      "|   15|         3375|\n",
      "|    1|            1|\n",
      "|  344|     40707584|\n",
      "|   15|         3375|\n",
      "|   62|       238328|\n",
      "|    1|            1|\n",
      "|   62|       238328|\n",
      "|  588|    203297472|\n",
      "|   40|        64000|\n",
      "|    1|            1|\n",
      "|  325|     34328125|\n",
      "|   39|        59319|\n",
      "|   64|       262144|\n",
      "|    1|            1|\n",
      "|   41|        68921|\n",
      "|   30|        27000|\n",
      "|    6|          216|\n",
      "|    4|           64|\n",
      "|  230|     12167000|\n",
      "|    1|            1|\n",
      "+-----+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def power3(num):\n",
    "    return num * num * num\n",
    "\n",
    "spark.udf.register(\"power3\", f=power3)\n",
    "\n",
    "sql = \"SELECT count, power3(count) FROM flight\"\n",
    "spark.sql(sql).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.10.3 서브 쿼리\n",
    "+ 비상호 연관쿼리: 서브쿼리와 연관된 정보를 사용하지 않음\n",
    "+ 상호 연관쿼리: 내부쿼리가 외부 쿼리의 결과를 참조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 비상호 연관쿼리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|dest_country_name|\n",
      "+-----------------+\n",
      "|    United States|\n",
      "|           Canada|\n",
      "|           Mexico|\n",
      "|   United Kingdom|\n",
      "|            Japan|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subsql = \"\"\"\n",
    "SELECT dest_country_name FROM flights\n",
    "GROUP BY dest_country_name ORDER BY sum(count) DESC LIMIT 5\n",
    "\"\"\"\n",
    "spark.sql(subsql).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|               Egypt|      United States|   15|\n",
      "|          Costa Rica|      United States|  588|\n",
      "|             Senegal|      United States|   40|\n",
      "|             Moldova|      United States|    1|\n",
      "|              Guyana|      United States|   64|\n",
      "|               Malta|      United States|    1|\n",
      "|            Anguilla|      United States|   41|\n",
      "|             Bolivia|      United States|   30|\n",
      "|             Algeria|      United States|    4|\n",
      "|Turks and Caicos ...|      United States|  230|\n",
      "|Saint Vincent and...|      United States|    1|\n",
      "|               Italy|      United States|  382|\n",
      "|            Pakistan|      United States|   12|\n",
      "|             Iceland|      United States|  181|\n",
      "|    Marshall Islands|      United States|   42|\n",
      "|          Luxembourg|      United States|  155|\n",
      "|            Honduras|      United States|  362|\n",
      "|         The Bahamas|      United States|  955|\n",
      "|         El Salvador|      United States|  561|\n",
      "|               Samoa|      United States|   25|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "SELECT * FROM flights\n",
    "WHERE origin_country_name IN\n",
    "    (SELECT dest_country_name FROM flights\n",
    "    GROUP BY dest_country_name ORDER BY sum(count) DESC LIMIT 5)\n",
    "\"\"\"\n",
    "spark.sql(sql).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 상호 연관쿼리\n",
    "목적기 국가에서 되돌아올 수 있는 항공편이 있는지 알고 싶다면 목적지 국가를 출발지 국가로, 출발지 국가를 목적기 국가로 설정하여 항공편이 있는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+\n",
      "|   DEST_COUNTRY_NAME| ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+--------------------+-----+\n",
      "|       United States|             Romania|   15|\n",
      "|       United States|             Croatia|    1|\n",
      "|       United States|             Ireland|  344|\n",
      "|               Egypt|       United States|   15|\n",
      "|       United States|               India|   62|\n",
      "|       United States|           Singapore|    1|\n",
      "|       United States|             Grenada|   62|\n",
      "|          Costa Rica|       United States|  588|\n",
      "|             Senegal|       United States|   40|\n",
      "|       United States|        Sint Maarten|  325|\n",
      "|       United States|    Marshall Islands|   39|\n",
      "|              Guyana|       United States|   64|\n",
      "|               Malta|       United States|    1|\n",
      "|            Anguilla|       United States|   41|\n",
      "|             Bolivia|       United States|   30|\n",
      "|       United States|            Paraguay|    6|\n",
      "|Turks and Caicos ...|       United States|  230|\n",
      "|               Italy|       United States|  382|\n",
      "|       United States|Federated States ...|   69|\n",
      "|       United States|              Russia|  161|\n",
      "+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "SELECT * FROM flights f1\n",
    "WHERE EXISTS (SELECT 1 FROM flights f2\n",
    "    WHERE f1.dest_country_name = f2.origin_country_name)\n",
    "AND EXISTS (SELECT 1 FROM flights f2\n",
    "    WHERE f2.dest_country_name = f1.origin_country_name)\n",
    "\"\"\"\n",
    "spark.sql(sql).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
