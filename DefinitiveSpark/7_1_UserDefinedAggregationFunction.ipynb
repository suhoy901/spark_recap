{"cells":[{"cell_type":"markdown","source":["- UDAF 는 스칼라와 자바로만 사용할 수 있음\n~~~\ninputSchema : UDAF 입력 파라미터의 스키마를 StructType으로 정의\nbufferSchema : UDAF 중간 결과를 스키마를 StuctType으로 정의\ndataType : 반환될 값의 DataType을 정의\ndeterministic : UDAF 가 동일한 입력값에 대해 항상 동일한 결과를 반환하는지 불리언값으로 정의\ninitialize : 집계용 버퍼의 값을 초기화하는 로직을 정의\nupdate : 입력받은 로우를 기반으로 내부 버퍼를 업데이트하는 로직을 정의\nmerge : 두 개의 집계용 버퍼를 병합하는 로직을 정의\nevaluate : 집계의 최동 결과를 생성하는 로직을 정의\n~~~"],"metadata":{}},{"cell_type":"code","source":["%scala\n\nimport org.apache.spark.sql.expressions.MutableAggregationBuffer\nimport org.apache.spark.sql.expressions.UserDefinedAggregateFunction\nimport org.apache.spark.sql._\nimport org.apache.spark.sql.types._\n\nclass BoolAnd extends UserDefinedAggregateFunction{\n  def inputSchema: StructType = \n  StructType(StructField(\"value\", BooleanType) :: Nil) // Nill 빈 리스트\n  def bufferSchema: StructType = \n  StructType(StructField(\"result\", BooleanType) :: Nil)\n  def dataType: DataType = BooleanType\n  def deterministic: Boolean = true\n  def initialize(buffer: MutableAggregationBuffer): Unit = { // Unit은 void개념\n    buffer(0) = true\n  }\n  def update(buffer: MutableAggregationBuffer, input: Row):Unit = {\n    buffer(0) = buffer.getAs[Boolean](0) && input.getAs[Boolean](0)\n  }\n  def merge(buffer1: MutableAggregationBuffer, buffer2 : Row) : Unit = {\n    buffer1(0) = buffer1.getAs[Boolean](0) && buffer2.getAs[Boolean](0)\n  }\n  def evaluate(buffer: Row): Any = {\n    buffer(0)\n  }\n}"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">import org.apache.spark.sql.expressions.MutableAggregationBuffer\nimport org.apache.spark.sql.expressions.UserDefinedAggregateFunction\nimport org.apache.spark.sql._\nimport org.apache.spark.sql.types._\ndefined class BoolAnd\n</div>"]}}],"execution_count":2},{"cell_type":"code","source":["%scala\n\nval ba = new BoolAnd\n\nspark.udf.register(\"booland\", ba)\nimport org.apache.spark.sql.functions._\n\nspark.range(1)\n  .selectExpr(\"explode(array(TRUE, TRUE, TRUE)) as t\") // 모든 컬럼이 True이면 true\n  .selectExpr(\"explode(array(TRUE, FALSE, TRUE)) as f\", \"t\") // 모든 컬럼이 true이면 false\n  .select(ba(col(\"t\")), expr(\"booland(f)\")).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+----------+\nbooland(t)|booland(f)|\n+----------+----------+\n      true|     false|\n+----------+----------+\n\nba: BoolAnd = BoolAnd@42641a84\nimport org.apache.spark.sql.functions._\n</div>"]}}],"execution_count":3},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":4}],"metadata":{"name":"7_1_UserDefinedAggregationFunction2","notebookId":676428912489825},"nbformat":4,"nbformat_minor":0}
